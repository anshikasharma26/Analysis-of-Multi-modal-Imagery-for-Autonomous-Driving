{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yolov3 video.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WTahs_ngxRE",
        "colab_type": "text"
      },
      "source": [
        "# Prepare YoloV3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PtfNmjCNmNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kojkXHYAL1Kf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd yolov3\n",
        "import time\n",
        "import glob\n",
        "import torch\n",
        "import os\n",
        "\n",
        "import argparse\n",
        "from sys import platform\n",
        "\n",
        "from models import *\n",
        "from utils.datasets import *\n",
        "from utils.utils import *\n",
        "\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--cfg', type=str, default='cfg/yolov3-spp.cfg', help='*.cfg path')\n",
        "parser.add_argument('--names', type=str, default='data/coco.names', help='*.names path')\n",
        "parser.add_argument('--weights', type=str, default='weights/yolov3-spp-ultralytics.pt', help='weights path')\n",
        "\n",
        "parser.add_argument('--img-size', type=int, default=416, help='inference size (pixels)')\n",
        "parser.add_argument('--conf-thres', type=float, default=0.3, help='object confidence threshold')\n",
        "parser.add_argument('--iou-thres', type=float, default=0.6, help='IOU threshold for NMS')\n",
        "\n",
        "\n",
        "parser.add_argument('--device', default='', help='device id (i.e. 0 or 0,1) or cpu')\n",
        "\n",
        "\n",
        "parser.add_argument('--classes', nargs='+', type=int, help='filter by class')\n",
        "parser.add_argument('--agnostic-nms', action='store_true', help='class-agnostic NMS')\n",
        "opt = parser.parse_args(args = [])\n",
        "\n",
        "weights = opt.weights\n",
        "img_size =  opt.img_size\n",
        "\n",
        "# Initialize\n",
        "device = torch_utils.select_device(device='cpu' if ONNX_EXPORT else opt.device)\n",
        "\n",
        "# Initialize model\n",
        "model = Darknet(opt.cfg, img_size)\n",
        "\n",
        "# Load weights\n",
        "attempt_download(weights)\n",
        "if weights.endswith('.pt'):  # pytorch format\n",
        "    model.load_state_dict(torch.load(weights, map_location=device)['model'])\n",
        "else:  # darknet format\n",
        "    load_darknet_weights(model, weights)\n",
        "\n",
        "model.to(device).eval();\n",
        "\n",
        "# Get names and colors\n",
        "names = load_classes(opt.names)\n",
        "colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(names))]\n",
        "\n",
        "%cd .. \n",
        "\n",
        "def predict_one_video(path_video, output_dir = 'output'): \n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    cap  = cv2.VideoCapture(path_video)\n",
        "    _, img0 = cap.read()\n",
        "\n",
        "    save_path = os.path.join(output_dir, os.path.split(path_video)[-1]) \n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'MP4V'), fps, (w, h))\n",
        "\n",
        "    while img0 is not None: \n",
        "\n",
        "        # Padded resize\n",
        "        img = letterbox(img0, new_shape=opt.img_size)[0]\n",
        "\n",
        "        # Convert\n",
        "        img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3xHxW\n",
        "        img = np.ascontiguousarray(img)\n",
        "\n",
        "        img = torch.from_numpy(img).to(device)\n",
        "        img = img.float()  # uint8 to fp16/32\n",
        "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
        "        if img.ndimension() == 3:\n",
        "            img = img.unsqueeze(0)\n",
        "\n",
        "        pred = model(img)[0]\n",
        "        # Apply NMS\n",
        "        pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres, classes=opt.classes, agnostic=opt.agnostic_nms)\n",
        "\n",
        "        # Process detections\n",
        "        for i, det in enumerate(pred):  # detections per image\n",
        "            im0 = img0 ##### Ganti im0s menjadi img0\n",
        "\n",
        "            if det is not None and len(det):\n",
        "                # Rescale boxes from img_size to im0 size\n",
        "                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
        "\n",
        "                # Write results\n",
        "                for *xyxy, conf, cls in det:\n",
        "                    label = '%s %.2f' % (names[int(cls)], conf)\n",
        "                    plot_one_box(xyxy, im0, label=label, color=colors[int(cls)])\n",
        "\n",
        "        vid_writer.write(im0)\n",
        "        _, img0 = cap.read()\n",
        "\n",
        "    vid_writer.release()\n",
        "\n",
        "    return save_path\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5SbLvzLU3i_",
        "colab_type": "text"
      },
      "source": [
        "# Git clone to get short videos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LEWy4FDUtXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/vindruid/yolov3-in-colab.git\n",
        "!cp -r \"yolov3-in-colab\"/input_video/* ./input_video/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NekDq0GwhmE4",
        "colab_type": "text"
      },
      "source": [
        "# Process Video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhOPbSjJVaD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p input_video\n",
        "!mkdir -p output_compressed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSytfayw0vyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_video = os.path.join(\"input_video\",\"opera_house.mp4\")\n",
        "save_path = predict_one_video(path_video)\n",
        "\n",
        "# Show video\n",
        "mp4 = open(path_video,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osBzRGoxMAE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compress video\n",
        "compressed_path = os.path.join(\"output_compressed\", os.path.split(save_path)[-1])\n",
        "os.system(f\"ffmpeg -i {save_path} -vcodec libx264 {compressed_path}\")\n",
        "\n",
        "# Show video\n",
        "mp4 = open(compressed_path,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47aetUx1Mm4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_video = os.path.join(\"input_video\",\"kitty.mp4\")\n",
        "save_path = predict_one_video(path_video)\n",
        "\n",
        "# compress video\n",
        "compressed_path = os.path.join(\"output_compressed\", os.path.split(save_path)[-1])\n",
        "os.system(f\"ffmpeg -i {save_path} -vcodec libx264 {compressed_path}\")\n",
        "\n",
        "# Show video\n",
        "mp4 = open(compressed_path,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLtgpkxyQUQ0",
        "colab_type": "text"
      },
      "source": [
        "To Process your own video, upload your video inside `input_video` folder "
      ]
    }
  ]
}